name: stable-diffusion-train

infer:
  unconditional_guidance_scale: 3
  num_images_per_prompt: 4
  hint_image_size: 512
  height: 512
  width: 512
  down_factor: 8
  inference_steps: 50
  sampler_type: 'DDIM'
  eta: 0
  output_type: 'pil'
  save_to_file: True
  out_path: 'controlnet'
  seed: 355
  prompts:
    - high quality picture of a house in oil painting style
  control:
    - /datasets/coco-stuff/house.png #images/val2017/000000001584.jpg
  # Depending on the input control, if the input control is already the conditioning image, null should be passed here
  # If a reconstruction target is used as control, then preprocessing function that turns it into a conditioning image needs to be specified
  control_image_preprocess:

trainer:
  devices: 1
  num_nodes: 1
  accelerator: gpu
  precision: 16
  logger: False # logger provided by exp_manager

model:
  restore_from_path: /ckpts/controlnet/30k.nemo
  precision: ${trainer.precision}
  strength: 2.0
  guess_mode: False