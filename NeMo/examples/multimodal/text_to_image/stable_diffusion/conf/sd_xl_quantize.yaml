trainer:
  devices: 1
  num_nodes: 1
  accelerator: gpu
  precision: 16
  logger: False # logger provided by exp_manager
  enable_checkpointing: False
  use_distributed_sampler: False
  max_epochs: -1 # PTL default. In practice, max_steps will be reached first.
  max_steps: -1 # consumed_samples = global_step * micro_batch_size * data_parallel_size * accumulate_grad_batches
  log_every_n_steps: 10
  accumulate_grad_batches: 1 # do not modify, grad acc is automatic for training megatron models
  gradient_clip_val: 1.0
  benchmark: False
  enable_model_summary: True
  limit_val_batches: 0


infer:
  num_samples: 4
  prompt:
    - "A professional photograph of an astronaut riding a pig"
    - 'A photo of a Shiba Inu dog with a backpack riding a bike. It is wearing sunglasses and a beach hat.'
    - 'A cute corgi lives in a house made out of sushi.'
    - 'A high contrast portrait of a very happy fuzzy panda dressed as a chef in a high end kitchen making dough. There is a painting of flowers on the wall behind him.'
    - 'A brain riding a rocketship heading towards the moon.'
  negative_prompt: ""
  seed: 123


sampling:
  base:
    sampler: EulerEDMSampler
    width: 1024
    height: 1024
    steps: ${quantize.n_steps}
    discretization: "LegacyDDPMDiscretization"
    guider: "VanillaCFG"
    thresholder: "None"
    scale: 5.0
    img2img_strength: 1.0
    sigma_min: 0.0292
    sigma_max: 14.6146
    rho: 3.0
    s_churn: 0.0
    s_tmin: 0.0
    s_tmax: 999.0
    s_noise: 1.0
    eta: 1.0
    order: 4
    orig_width: 1024
    orig_height: 1024
    crop_coords_top: 0
    crop_coords_left: 0

model:
  restore_from_path:
  is_legacy: False

quantize:
  exp_name: nemo_test
  n_steps: 20          # number of inference steps
  format: 'int8'       # only int8 quantization is supported now
  percentile: 1.0      # Control quantization scaling factors (amax) collecting range, meaning that we will collect the minimum amax in the range of `(n_steps * percentile)` steps. Recommendation: 1.0
  batch_size: 1        # batch size calling sdxl inference pipeline during calibration
  calib_size: 32       # For SDXL, we recommend 32, 64 or 128
  quant_level: 2.5     #Which layers to be quantized, 1: `CNNs`, 2: `CNN + FFN`, 2.5: `CNN + FFN + QKV`, 3: `CNN + Linear`. Recommendation: 2, 2.5 and 3, depending on the requirements for image quality & speedup.
  alpha: 0.8           # A parameter in SmoothQuant, used for linear layers only. Recommendation: 0.8 for SDXL
  quantized_ckpt: nemo.unet.state_dict.${quantize.exp_name}.pt

onnx_export:
  onnx_dir: nemo_onnx  # Path to save onnx files
  pretrained_base: ${model.restore_from_path}  # Path to nemo checkpoint for sdxl
  quantized_ckpt: ${quantize.quantized_ckpt}  # Path to save quantized unet checkpoint
  format: int8

trt_export:
  static_batch: False # static batch engines have better latency
  min_batch_size: 1   # minimum batch size when using dynamic batch, has to be the same with max_batch_size and infer.num_samples when using static batch
  max_batch_size: 8   # maximum batch size when using dynamic batch, has to be the same with min_batch_size and infer.num_samples when using static batch
  int8: True          # Allow engine builder recognize int8 precision
  builder_optimization_level: 4  # set to 1-5, higher optimization level means better latency but longer compiling time
  trt_engine: int8_unet_xl.plan  # path to save trt engine

use_refiner: False
use_fp16: False # use fp16 model weights
out_path: ./output
run_quantization: True
run_onnx_export: True
run_trt_export: True

