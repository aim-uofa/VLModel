# this file main purpose is documentation, and it should not be used directly 
enc_output_name: z # name of key in hidden transforms output to pass to decoder (default: hiddens). e.g., z for VAE/MIM.
tokens_loss_weight: 1.0 # weight of tokens loss (if not specified defaults to 1.0)
# the lists below are useful for adding multiple transforms and losses according to order
# if order is not important, you can use a single dictionary in the list with multiple keys
transform: # a list of dictionaries of transforms (or a joint dictionary) to apply to hiddens (list enforces order)
  # - <transform_name>: # name of transform
  #     cls_name: <a registered transformation class name> # class name
  #     <transform_param>: <transform_value> # transform parameters
  #     ...
  - q_z_given_x: # Gaussian posterior with reparameterization
      cls_name: cond_gaussian # class name
      hidden_size: 512 # hidden size of the encoder
      min_logvar: -6.0 # minimum log variance
  - logP_cls: # logP classifier logits
      cls_name: guided_cls
      input_name: hiddens
      attr_name: logP
    QED_cls: # QED classifier logits
      cls_name: guided_cls
      input_name: hiddens
      attr_name: QED
loss: # a list of dictionaries of loss terms (or a joint dictionary) to add to reconstruction loss (list enforces order)
  # - <loss_name>: # name of loss
  #     cls_name: <a registered loss class name> # class name
  #     <loss_param>: <loss_value> # loss parameters
  #     ...
  # below is example where order of losses does not matter so a single dictionary is enough
  mim: # A-MIM example
    cls_name: a_mim
    loss_weight: 1.0 # weight of the MIM latent loss
  vae: # VAE example
      cls_name: vae
      min_kl_value: null # minimum KL value if a float is provided
      loss_weight: 1e-2 # weight of KL term in loss
  logP_cls: # logP classifier loss (cross entropy)
      cls_name: guided_cls_loss
      input_name: logP
      loss_weight: 0.1
  QED_cls: # QED classifier loss (cross entropy)
      cls_name: guided_cls_loss
      input_name: logP
      loss_weight: 0.1
