name: &name "Jasper10x5"

model:
  sample_rate: &sample_rate 16000
  labels: &labels [" ", "a", "b", "c", "d", "e", "f", "g", "h", "i", "j", "k", "l", "m",
                   "n", "o", "p", "q", "r", "s", "t", "u", "v", "w", "x", "y", "z", "'"]

  train_ds:
    manifest_filepath: ???
    sample_rate: 16000
    labels: *labels
    batch_size: 32
    trim_silence: True
    max_duration: 16.7
    shuffle: True
    num_workers: 8
    pin_memory: true
    # tarred datasets
    is_tarred: false
    tarred_audio_filepaths: null
    tarred_shard_strategy: "scatter"
    shuffle_n: 2048
    # bucketing params
    bucketing_strategy: "synced_randomized"
    bucketing_batch_size: null

  validation_ds:
    manifest_filepath: ???
    sample_rate: 16000
    labels: *labels
    batch_size: 32
    shuffle: False
    num_workers: 8
    pin_memory: true

  preprocessor:
    _target_: nemo.collections.asr.modules.AudioToMelSpectrogramPreprocessor
    normalize: "per_feature"
    window_size: 0.02
    sample_rate: *sample_rate
    window_stride: 0.01
    window: "hann"
    features: &n_mels 64
    n_fft: 512
    frame_splicing: 1
    dither: 0.00001

  spec_augment:
    _target_: nemo.collections.asr.modules.SpectrogramAugmentation
    rect_freq: 50
    rect_masks: 5
    rect_time: 120

  encoder:
    _target_: nemo.collections.asr.modules.ConvASREncoder
    feat_in: *n_mels
    activation: relu
    conv_mask: true
    jasper:
      - dilation: [1]
        dropout: 0.2
        filters: 256
        kernel: [11]
        repeat: 1
        residual: false
        stride: [2]
      - dilation: [1]
        dropout: 0.2
        filters: 256
        kernel: [11]
        repeat: 5
        residual: true
        residual_dense: true
        stride: [1]
      - dilation: [1]
        dropout: 0.2
        filters: 256
        kernel: [11]
        repeat: 5
        residual: true
        residual_dense: true
        stride: [1]
      - dilation: [1]
        dropout: 0.2
        filters: 384
        kernel: [13]
        repeat: 5
        residual: true
        residual_dense: true
        stride: [1]
      - dilation: [1]
        dropout: 0.2
        filters: 384
        kernel: [13]
        repeat: 5
        residual: true
        residual_dense: true
        stride: [1]
      - dilation: [1]
        dropout: 0.2
        filters: 512
        kernel: [17]
        repeat: 5
        residual: true
        residual_dense: true
        stride: [1]
      - dilation: [1]
        dropout: 0.2
        filters: 512
        kernel: [17]
        repeat: 5
        residual: true
        residual_dense: true
        stride: [1]
      - dilation: [1]
        dropout: 0.3
        filters: 640
        kernel: [21]
        repeat: 5
        residual: true
        residual_dense: true
        stride: [1]
      - dilation: [1]
        dropout: 0.3
        filters: 640
        kernel: [21]
        repeat: 5
        residual: true
        residual_dense: true
        stride: [1]
      - dilation: [1]
        dropout: 0.3
        filters: 768
        kernel: [25]
        repeat: 5
        residual: true
        residual_dense: true
        stride: [1]
      - dilation: [1]
        dropout: 0.3
        filters: 768
        kernel: [25]
        repeat: 5
        residual: true
        residual_dense: true
        stride: [1]
      - dilation: [2]
        dropout: 0.4
        filters: 896
        kernel: [29]
        repeat: 1
        residual: false
        stride: [1]
      - dilation: [1]
        dropout: 0.4
        filters: 1024
        kernel: [1]
        repeat: 1
        residual: false
        stride: [1]

  decoder:
    _target_: nemo.collections.asr.modules.ConvASRDecoder
    feat_in: 1024
    num_classes: 28
    vocabulary: *labels

  optim:
    name: novograd
    # _target_: nemo.core.optim.optimizers.Novograd
    lr: .01
    # optimizer arguments
    betas: [0.8, 0.5]
    weight_decay: 0.001

    # scheduler setup
    sched:
      name: CosineAnnealing

      # pytorch lightning args
      # monitor: val_loss
      # reduce_on_plateau: false

      # Scheduler params
      warmup_steps: null
      warmup_ratio: null
      min_lr: 0.0
      last_epoch: -1

trainer:
  devices: 1 # number of gpus
  max_epochs: 5
  max_steps: -1 # computed at runtime if not set
  num_nodes: 1
  accelerator: gpu
  strategy: ddp
  accumulate_grad_batches: 1
  enable_checkpointing: False  # Provided by exp_manager
  logger: False  # Provided by exp_manager
  log_every_n_steps: 1  # Interval of logging.
  val_check_interval: 1.0  # Set to 0.25 to check 4 times per epoch, or an int for number of iterations
  benchmark: false # needs to be false for models with variable-length speech input as it slows down training

exp_manager:
  exp_dir: null
  name: *name
  create_tensorboard_logger: True
  create_checkpoint_callback: True
  create_wandb_logger: False
  wandb_logger_kwargs:
    name: null
    project: null

hydra:
  run:
    dir: .
  job_logging:
    root:
      handlers: null
